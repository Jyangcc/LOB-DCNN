{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLOB: Deep Convolutional Neural Networks for Limit Order Books\n",
    "\n",
    "### Authors: Zihao Zhang, Stefan Zohren and Stephen Roberts\n",
    "Oxford-Man Institute of Quantitative Finance, Department of Engineering Science, University of Oxford\n",
    "\n",
    "This jupyter notebook is used to demonstrate our recent paper [2] published in IEEE Transactions on Singal Processing. We use FI-2010 [1] dataset and present how model architecture is constructed here. \n",
    "\n",
    "### Data:\n",
    "The FI-2010 is publicly avilable and interested readers can check out their paper [1]. The dataset can be downloaded from: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649 \n",
    "\n",
    "Otherwise, the notebook will download the data automatically or it can be obtained from: \n",
    "\n",
    "https://drive.google.com/drive/folders/1Xen3aRid9ZZhFqJRgEMyETNazk02cNmv?usp=sharing\n",
    "\n",
    "### References:\n",
    "[1] Ntakaris A, Magris M, Kanniainen J, Gabbouj M, Iosifidis A. Benchmark dataset for mid‐price forecasting of limit order book data with machine learning methods. Journal of Forecasting. 2018 Dec;37(8):852-66. https://arxiv.org/abs/1705.03233\n",
    "\n",
    "[2] Zhang Z, Zohren S, Roberts S. DeepLOB: Deep convolutional neural networks for limit order books. IEEE Transactions on Signal Processing. 2019 Mar 25;67(11):3001-12. https://arxiv.org/abs/1808.03668\n",
    "\n",
    "### This notebook runs on Pytorch 1.9.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# if not os.path.isfile('data.zip'):\n",
    "#     !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n",
    "#     !unzip -n data.zip\n",
    "#     print('data downloaded.')\n",
    "# else:\n",
    "#     print('data already existed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
    "# N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "    # Create a Tensor directly on the mps device\n",
    "    x = torch.ones(5, device=mps_device)\n",
    "    # Or\n",
    "    x = torch.ones(5, device=\"mps\")\n",
    "    \n",
    "print(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "\n",
    "    dY = np.array(Y)\n",
    "\n",
    "    dataY = dY[T - 1:N]\n",
    "\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    \n",
    "    \n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "        \n",
    "    return dataX, dataY\n",
    "\n",
    "def torch_data(x, y):\n",
    "    x = torch.from_numpy(x)\n",
    "    x = torch.unsqueeze(x, 1)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = F.one_hot(y, num_classes=3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
    "    def __init__(self, data, k, num_classes, T):\n",
    "        \"\"\"Initialization\"\"\" \n",
    "        self.k = k\n",
    "        self.num_classes = num_classes\n",
    "        self.T = T\n",
    "            \n",
    "        x = prepare_x(data)\n",
    "        y = get_label(data)\n",
    "        \n",
    "        x, y = data_classification(x, y, self.T)\n",
    "        y = y[:,self.k] - 1\n",
    "        \n",
    "        \n",
    "        self.length = len(x)\n",
    "\n",
    "        x = torch.from_numpy(x)\n",
    "        self.x = torch.unsqueeze(x, 1)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates samples of data\"\"\"\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We used no auction dataset that is normalised by decimal precision approach in their work. The first seven days are training data and the last three days are testing data. A validation set (20%) from the training set is used to monitor the overfitting behaviours.  \n",
    "\n",
    "The first 40 columns of the FI-2010 dataset are 10 levels ask and bid information for a limit order book and we only use these 40 features in our network. The last 5 columns of the FI-2010 dataset are the labels with different prediction horizons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 62327) (149, 15582)\n"
     ]
    }
   ],
   "source": [
    "# please change the data_path to your local path\n",
    "\n",
    "dec_data = np.loadtxt('../BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_2.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "# dec_test1 = np.loadtxt('../../BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_2.txt')\n",
    "# dec_test2 = np.loadtxt('../../BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_3.txt')\n",
    "# dec_test3 = np.loadtxt('../../BenchmarkDatasets/NoAuction/3.NoAuction_DecPre/NoAuction_DecPre_Training/Train_Dst_NoAuction_DecPre_CF_4.txt')\n",
    "# dec_test = np.hstack((dec_test1, dec_test2))\n",
    "\n",
    "# print(dec_train.shape, dec_val.shape, dec_test.shape)\n",
    "\n",
    "print(dec_train.shape, dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape =  (62327, 40)\n",
      "y shape =  (62327, 5)\n",
      "--------------------------------\n",
      "x shape =  (62288, 40, 40)\n",
      "y shape =  (62288,)\n",
      "x shape =  (15582, 40)\n",
      "y shape =  (15582, 5)\n",
      "--------------------------------\n",
      "x shape =  (15543, 40, 40)\n",
      "y shape =  (15543,)\n",
      "torch.Size([62288, 1, 40, 40]) torch.Size([62288])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=40)\n",
    "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=40)\n",
    "# dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=40)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(dataset_train.x.shape, dataset_train.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1264, 0.0439, 0.1262,  ..., 0.0100, 0.1253, 0.0083],\n",
      "          [0.1264, 0.0615, 0.1263,  ..., 0.0100, 0.1254, 0.0265],\n",
      "          [0.1264, 0.0615, 0.1263,  ..., 0.0100, 0.1254, 0.0265],\n",
      "          ...,\n",
      "          [0.1266, 0.0197, 0.1262,  ..., 0.0100, 0.1252, 0.0267],\n",
      "          [0.1265, 0.0032, 0.1262,  ..., 0.0043, 0.1252, 0.0267],\n",
      "          [0.1266, 0.0164, 0.1262,  ..., 0.3210, 0.1252, 0.0267]]]],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.], dtype=torch.float64)\n",
      "torch.Size([1, 1, 40, 40]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "tmp_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=1, shuffle=True)\n",
    "\n",
    "for x, y in tmp_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "Please find the detailed discussion of our model architecture in our paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class smalldeeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=24, hidden_size=16, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(16, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 16).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 16).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deeplob(nn.Module):\n",
    "    def __init__(self, y_len):\n",
    "        super().__init__()\n",
    "        self.y_len = y_len\n",
    "        \n",
    "        # convolution blocks\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "#             nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # inception moduels\n",
    "        self.inp1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.inp2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(5,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        self.inp3 = nn.Sequential(\n",
    "            nn.MaxPool2d((3, 1), stride=(1, 1), padding=(1, 0)),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,1), padding='same'),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "        \n",
    "        # lstm layers\n",
    "        self.lstm = nn.LSTM(input_size=96, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(32, self.y_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h0: (number of hidden layers, batch size, hidden size)\n",
    "        h0 = torch.zeros(1, x.size(0), 32).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), 32).to(device)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x_inp1 = self.inp1(x)\n",
    "        x_inp2 = self.inp2(x)\n",
    "        x_inp3 = self.inp3(x)  \n",
    "        \n",
    "        x = torch.cat((x_inp1, x_inp2, x_inp3), dim=1)\n",
    "        \n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
    "        \n",
    "\n",
    "        \n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        forecast_y = torch.softmax(x, dim=1)\n",
    "        \n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "smalldeeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(8, 8, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(8, 8, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(8, 8, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 8, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(8, 8, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(24, 16, batch_first=True)\n",
       "  (fc1): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = dataset_train.num_classes) # Change to small modle for testing \n",
    "print(device)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary(model, (1, 1, 100, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
    "    \n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    best_test_loss = np.inf\n",
    "    best_test_epoch = 0\n",
    "\n",
    "    for it in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for inputs, targets in train_loader:\n",
    "            # move data to GPU\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "            # print(\"inputs.shape:\", inputs.shape)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            # print(\"about to get model output\")\n",
    "            outputs = model(inputs)\n",
    "            # print(\"done getting model output\")\n",
    "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward and optimize\n",
    "            # print(\"about to optimize\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            torch.save(model, './best_val_model_pytorch')\n",
    "            best_test_loss = test_loss\n",
    "            best_test_epoch = it\n",
    "            print('model saved')\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:02<09:23, 62.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 1/10, Train Loss: 1.0739,           Validation Loss: 1.0816, Duration: 0:01:02.663938, Best Val Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:04<08:15, 61.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 2/10, Train Loss: 1.0334,           Validation Loss: 1.0601, Duration: 0:01:01.363236, Best Val Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:05<07:11, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 3/10, Train Loss: 1.0116,           Validation Loss: 1.0517, Duration: 0:01:01.234058, Best Val Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:06<06:07, 61.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 4/10, Train Loss: 0.9995,           Validation Loss: 1.0454, Duration: 0:01:00.755449, Best Val Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:06<05:05, 61.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 5/10, Train Loss: 0.9909,           Validation Loss: 1.0329, Duration: 0:01:00.832365, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:07<04:04, 61.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.9816,           Validation Loss: 1.0391, Duration: 0:01:00.827790, Best Val Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:08<03:02, 60.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 7/10, Train Loss: 0.9731,           Validation Loss: 1.0268, Duration: 0:01:00.737860, Best Val Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [08:09<02:02, 61.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "Epoch 8/10, Train Loss: 0.9643,           Validation Loss: 1.0237, Duration: 0:01:01.298508, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:14<01:02, 62.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.9557,           Validation Loss: 1.0398, Duration: 0:01:04.405090, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:20<00:00, 62.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.9486,           Validation Loss: 1.0270, Duration: 0:01:06.112706, Best Val Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
    "                                    train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f81b3ae7a60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5458\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_val_model_pytorch')\n",
    "\n",
    "n_correct = 0.\n",
    "n_total = 0.\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # update counts\n",
    "    n_correct += (predictions == targets).sum().item()\n",
    "    n_total += targets.shape[0]\n",
    "\n",
    "test_acc = n_correct / n_total\n",
    "print(f\"Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('best_val_model_pytorch')\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "\n",
    "for inputs, targets in test_loader:\n",
    "    # Move to GPU\n",
    "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get prediction\n",
    "    # torch.max returns both max and argmax\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    all_targets.append(targets.cpu().numpy())\n",
    "    all_predictions.append(predictions.cpu().numpy())\n",
    "\n",
    "all_targets = np.concatenate(all_targets)    \n",
    "all_predictions = np.concatenate(all_predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.5457859956378789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5518    0.6035    0.5765     75413\n",
      "           1     0.6570    0.4533    0.5365     38299\n",
      "           2     0.5002    0.5343    0.5167     70602\n",
      "\n",
      "    accuracy                         0.5458    184314\n",
      "   macro avg     0.5697    0.5304    0.5432    184314\n",
      "weighted avg     0.5539    0.5458    0.5453    184314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
    "print(classification_report(all_targets, all_predictions, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
